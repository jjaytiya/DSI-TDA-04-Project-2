{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = pd.read_csv('../datasets/train_clean.csv')\n",
    "test_df = pd.read_csv('../datasets/test_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 164)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 163)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_station_columns = [col for col in train_clean.columns if col.startswith('station_name_')]\n",
    "len(dummy_station_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train but not in test: {'price'}\n",
      "\n",
      "In test but not in train: set()\n"
     ]
    }
   ],
   "source": [
    "# Check why there is not the same column shape\n",
    "train_columns = set(train_clean.columns)\n",
    "test_columns = set(test_df.columns)\n",
    "\n",
    "# Columns in train but not in test\n",
    "train_not_in_test = train_columns - test_columns\n",
    "\n",
    "# Columns in test but not in train\n",
    "test_not_in_train = test_columns - train_columns\n",
    "\n",
    "print(\n",
    "    f\"In train but not in test: {train_not_in_test}\\n\\n\"\n",
    "    f\"In test but not in train: {test_not_in_train}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy station columns\n",
    "dummy_station_columns = [col for col in train_clean.columns if col.startswith('station_name')]\n",
    "\n",
    "# Feature set\n",
    "# Define the feature columns\n",
    "feature_cols1 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', 'floor_level', 'facilities', \n",
    "                 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "feature_cols2 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'nearby_stations', 'year_built', 'total_units', 'floor_level', 'facilities', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House']\n",
    "feature_cols3 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'Nonthaburi', 'Samut Prakan'] + dummy_station_columns\n",
    "feature_cols4 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_stations', \n",
    "                 'year_built', 'nearby_shops', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns \n",
    "feature_cols5 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_stations', \n",
    "                 'year_built', 'latitude', 'longitude', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns \n",
    "feature_cols6 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'nearby_stations', 'year_built', 'total_units', 'floor_level', 'facilities', \n",
    "                 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "feature_cols6 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'year_built', 'total_units', 'floor_level', 'facilities', \n",
    "                 'nearby_stations','Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "feature_cols7 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'nearby_stations','total_units', 'floor_level', 'facilities', \n",
    "                 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "# Define feature set\n",
    "feature_sets = [\n",
    "    (feature_cols1, 'Model 1'),\n",
    "    (feature_cols2, 'Model 2'),\n",
    "    (feature_cols3, 'Model 3'),\n",
    "    (feature_cols4, 'Model 4'),\n",
    "    (feature_cols5, 'Model 5'),\n",
    "    (feature_cols6, 'Model 6'),\n",
    "    (feature_cols7, 'Model 7')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model 1\n",
      "RMSE: 1287542.5676, R-squared: 0.6475\n",
      "\n",
      "Evaluating Model 2\n",
      "RMSE: 1410255.7794, R-squared: 0.5771\n",
      "\n",
      "Evaluating Model 3\n",
      "RMSE: 1456995.1504, R-squared: 0.5486\n",
      "\n",
      "Evaluating Model 4\n",
      "RMSE: 1276346.6992, R-squared: 0.6536\n",
      "\n",
      "Evaluating Model 5\n",
      "RMSE: 1301603.6017, R-squared: 0.6397\n",
      "\n",
      "Evaluating Model 6\n",
      "RMSE: 1243351.2399, R-squared: 0.6713\n",
      "\n",
      "Evaluating Model 7\n",
      "RMSE: 1260312.9358, R-squared: 0.6622\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(train_data, feature_set, target, model):\n",
    "  \n",
    "    # Define features and target variable\n",
    "    X = train_data[feature_set]  # Predictor variables\n",
    "    y = train_data[target]  # Target variable\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_dev)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "    r2 = r2_score(y_dev, y_pred)\n",
    "\n",
    "    # Prepare metrics for return\n",
    "    metrics = {\n",
    "        'RMSE': rmse,\n",
    "        'R-squared': r2\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Run on the feature sets\n",
    "for feature_set, model_name in feature_sets:\n",
    "    print(f\"\\nEvaluating {model_name}\")\n",
    "    \n",
    "    # Instantiate the model\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # Call the train_and_evaluate function\n",
    "    metrics = train_and_evaluate(train_clean, feature_set, 'price', lr)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"RMSE: {metrics['RMSE']:.4f}, R-squared: {metrics['R-squared']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 163)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
