{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, HuberRegressor, RANSACRegressor\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = pd.read_csv('../datasets/train_clean.csv')\n",
    "test_df = pd.read_csv('../datasets/test_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 164)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 163)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy station columns\n",
    "dummy_station_columns = [col for col in train_clean.columns if col.startswith('station_name')]\n",
    "\n",
    "# Feature set\n",
    "# Define the feature columns\n",
    "feature_cols1 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', 'floor_level', 'facilities', \n",
    "                 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "feature_cols2 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'nearby_stations', 'year_built', 'total_units', 'floor_level', 'facilities', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House']\n",
    "feature_cols3 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'Nonthaburi', 'Samut Prakan'] + dummy_station_columns\n",
    "feature_cols4 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_stations', \n",
    "                 'year_built', 'nearby_shops', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns \n",
    "feature_cols5 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops','nearby_stations', \n",
    "                'latitude', 'longitude', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns \n",
    "feature_cols6 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'nearby_stations', 'year_built', 'total_units', 'floor_level', 'facilities', \n",
    "                 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "feature_cols6 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'year_built', 'total_units', 'floor_level', 'facilities', \n",
    "                 'nearby_stations','Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "feature_cols7 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops', 'nearby_supermarkets', \n",
    "                 'nearby_stations','total_units', 'floor_level', 'facilities', \n",
    "                 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns\n",
    "# Define feature set\n",
    "feature_sets = [\n",
    "    (feature_cols1, 'Model 1'),\n",
    "    (feature_cols2, 'Model 2'),\n",
    "    (feature_cols3, 'Model 3'),\n",
    "    (feature_cols4, 'Model 4'),\n",
    "    (feature_cols5, 'Model 5'),\n",
    "    (feature_cols6, 'Model 6'),\n",
    "    (feature_cols7, 'Model 7')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Model 1:\n",
      "RidgeCV: RMSE = 1,287,667.20, R² = 0.65\n",
      "LassoCV: RMSE = 1,288,812.11, R² = 0.65\n",
      "Huber: RMSE = 1,295,719.51, R² = 0.64\n",
      "RANSAC: RMSE = 27,992,916,530,805,092,352.00, R² = -166626880022627845398331392.00\n",
      "Decision Tree: RMSE = 1,269,712.77, R² = 0.66\n",
      "\n",
      "\n",
      "Results for Model 2:\n",
      "RidgeCV: RMSE = 1,410,370.63, R² = 0.58\n",
      "LassoCV: RMSE = 1,410,377.27, R² = 0.58\n",
      "Huber: RMSE = 1,419,004.59, R² = 0.57\n",
      "RANSAC: RMSE = 1,609,639.70, R² = 0.45\n",
      "Decision Tree: RMSE = 1,289,160.99, R² = 0.65\n",
      "\n",
      "\n",
      "Results for Model 3:\n",
      "RidgeCV: RMSE = 1,456,909.99, R² = 0.55\n",
      "LassoCV: RMSE = 1,454,383.44, R² = 0.55\n",
      "Huber: RMSE = 1,469,918.21, R² = 0.54\n",
      "RANSAC: RMSE = 136,708,234,936,948,654,080.00, R² = -3974093826225038843394916352.00\n",
      "Decision Tree: RMSE = 1,314,711.61, R² = 0.63\n",
      "\n",
      "\n",
      "Results for Model 4:\n",
      "RidgeCV: RMSE = 1,276,577.54, R² = 0.65\n",
      "LassoCV: RMSE = 1,276,417.79, R² = 0.65\n",
      "Huber: RMSE = 1,289,523.44, R² = 0.65\n",
      "RANSAC: RMSE = 47,574,958,663,483,179,008.00, R² = -481288631563725076697186304.00\n",
      "Decision Tree: RMSE = 1,180,317.82, R² = 0.70\n",
      "\n",
      "\n",
      "Results for Model 5:\n",
      "RidgeCV: RMSE = 1,333,783.06, R² = 0.62\n",
      "LassoCV: RMSE = 1,333,178.98, R² = 0.62\n",
      "Huber: RMSE = 1,344,170.23, R² = 0.62\n",
      "RANSAC: RMSE = 29,096,594,836,909,191,168.00, R² = -180025115186422178713174016.00\n",
      "Decision Tree: RMSE = 1,079,483.46, R² = 0.75\n",
      "\n",
      "\n",
      "Results for Model 6:\n",
      "RidgeCV: RMSE = 1,243,627.13, R² = 0.67\n",
      "LassoCV: RMSE = 1,244,714.77, R² = 0.67\n",
      "Huber: RMSE = 1,251,755.37, R² = 0.67\n",
      "RANSAC: RMSE = 23,658,494,884,326,846,464.00, R² = -119020833769064236064964608.00\n",
      "Decision Tree: RMSE = 1,193,506.97, R² = 0.70\n",
      "\n",
      "\n",
      "Results for Model 7:\n",
      "RidgeCV: RMSE = 1,260,554.31, R² = 0.66\n",
      "LassoCV: RMSE = 1,261,259.59, R² = 0.66\n",
      "Huber: RMSE = 1,267,125.42, R² = 0.66\n",
      "RANSAC: RMSE = 28,772,615,102,183,002,112.00, R² = -176038409617083016132165632.00\n",
      "Decision Tree: RMSE = 1,215,252.88, R² = 0.69\n",
      "\n",
      "\n",
      "The model with the lowest RMSE is: Model 5 - Decision Tree with an RMSE of 1,079,483.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor  # Import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def run_models(X, y):\n",
    "    # Apply scale to improve convergence \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)  # 80:20\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'RidgeCV': RidgeCV(),\n",
    "        'LassoCV': LassoCV(),\n",
    "        'Huber': HuberRegressor(max_iter=2000),  # Increased max_iter \n",
    "        'RANSAC': RANSACRegressor(),\n",
    "        'Decision Tree': DecisionTreeRegressor()  # Add Decision Tree model. \n",
    "    }\n",
    "    \n",
    "    # Store results\n",
    "    results = {}\n",
    "\n",
    "    # Fit models and calculate RMSE and R^2\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)  # Calculate R^2 score\n",
    "        \n",
    "        results[model_name] = {'RMSE': rmse, 'R^2': r2}  # Store both metrics\n",
    "\n",
    "    return results\n",
    "\n",
    "# Create variables to track model that hase the best RMSE \n",
    "best_rmse = float('inf')  # Start with infinity as the best RMSE\n",
    "best_model = None         # To store the name of the best model\n",
    "\n",
    "\n",
    "# Iterate through each feature set and run the models\n",
    "for feature_cols, model_name in feature_sets:\n",
    "    X = train_clean[feature_cols]  # Select the features based on the current feature set\n",
    "    y = train_clean['price']        # Target variable\n",
    "\n",
    "    # Run models for the feature set\n",
    "    results = run_models(X, y)\n",
    "\n",
    "    # Print the results \n",
    "    print(f\"Results for {model_name}:\")\n",
    "    for model, metrics in results.items():\n",
    "        print(f\"{model}: RMSE = {metrics['RMSE']:,.2f}, R² = {metrics['R^2']:.2f}\")\n",
    "        \n",
    "        # Check which model has the lowest RMSE\n",
    "        if metrics['RMSE'] < best_rmse:\n",
    "            best_rmse = metrics['RMSE']\n",
    "            best_model = f\"{model_name} - {model}\"  # Include the feature set name\n",
    "\n",
    "    print(\"\\n\")  \n",
    "\n",
    "# Print the model with the lowest RMSE\n",
    "print(f\"The model with the lowest RMSE is: {best_model} with an RMSE of {best_rmse:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 163)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
