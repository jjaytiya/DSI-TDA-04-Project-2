{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, HuberRegressor, RANSACRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = pd.read_csv('../datasets/train_clean.csv')\n",
    "test_df = pd.read_csv('../datasets/test_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 164)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 163)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted with test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 5, 'min_samples_split': 16}\n",
      "Train R-squared Score: 0.88\n",
      "Test R-squared Score: 0.77\n",
      "RMSE: 1031504.91, R-squared: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Get dummy station columns\n",
    "dummy_station_columns = [col for col in train_clean.columns if col.startswith('station_name')]\n",
    "feature_cols5 = ['bedrooms', 'baths', 'land_area', 'floor_area', 'nearby_bus_stops','nearby_stations', \n",
    "                'latitude', 'longitude', 'Nonthaburi', 'Samut Prakan', 'Townhouse', 'Detached House'] + dummy_station_columns \n",
    "\n",
    "\n",
    "X = train_clean [feature_cols5]\n",
    "y = train_clean['price']  \n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "# Expanded parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [None, 3, 5, 7, 10, 15, 20,25],\n",
    "    'min_samples_split': [2, 4, 8, 12, 16],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 7, 10] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "# Instantiate the best model\n",
    "best_dt = DecisionTreeRegressor(**best_params)\n",
    "best_dt.fit(X_train, y_train)\n",
    "\n",
    "# Train score\n",
    "train_score = best_dt.score(X_train, y_train)\n",
    "print(f'Train R-squared Score: {train_score:.2f}')\n",
    "\n",
    "# Test score\n",
    "test_score = best_dt.score(X_dev, y_dev)\n",
    "print(f'Test R-squared Score: {test_score:.2f}')\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_test_pred = best_dt.predict(X_dev)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "r2 = r2_score(y_dev, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'RMSE: {rmse:.2f}, R-squared: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated R-squared Scores: [0.76835486 0.76954568 0.7706113  0.76735195 0.76781805]\n",
      "Average Cross-Validated R-squared: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(best_dt, X, y, cv=5, scoring='r2')\n",
    "print(f'Cross-Validated R-squared Scores: {cv_scores}')\n",
    "print(f'Average Cross-Validated R-squared: {np.mean(cv_scores):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 164)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 163)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features for the test DataFrame\n",
    "X_test = test_df[feature_cols5]  \n",
    "\n",
    "# Fill missing values with 0 (or handle them differently based on your preprocessing)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Add the predictions to the test DataFrame\n",
    "test_df['price'] = y_test_pred\n",
    "\n",
    "# Save the results to a CSV file\n",
    "test_df[['id', 'price']].to_csv('../datasets/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
